{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de2d08d8",
   "metadata": {},
   "source": [
    "# Data Restructure\n",
    "\n",
    "We will now attempt to combine our data and convert it into a more visualization friendly long format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c75e96",
   "metadata": {},
   "source": [
    "## Start by combining files in a folder\n",
    "\n",
    "We will follow the following steps:\n",
    "1. collect all games/lobbies of the same round\n",
    "2. collect all rounds of the same level\n",
    "2. collect all levels\n",
    "3. collect all regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0810a4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32d2279c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standings</th>\n",
       "      <th>Team.1</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>FC Destroy</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Dps</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>CJAM</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>sspZ</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Joel Mark</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Standings      Team.1  Total\n",
       "0        1.0  FC Destroy    112\n",
       "1        2.0         Dps     38\n",
       "2        3.0        CJAM     32\n",
       "3        4.0        sspZ     31\n",
       "4        5.0   Joel Mark     24"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with looking at our cleaned data:\n",
    "directory = '../Outputs/APAC_North/Preseason_Qualifier_1/Round_1/Cleaned'\n",
    "\n",
    "df = pd.read_csv(f\"{directory}/Lobby 1_cleaned.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "659678eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standings</th>\n",
       "      <th>Team.1</th>\n",
       "      <th>Total</th>\n",
       "      <th>Lobby</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>FC Destroy</td>\n",
       "      <td>112</td>\n",
       "      <td>Lobby 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Dps</td>\n",
       "      <td>38</td>\n",
       "      <td>Lobby 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>CJAM</td>\n",
       "      <td>32</td>\n",
       "      <td>Lobby 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>sspZ</td>\n",
       "      <td>31</td>\n",
       "      <td>Lobby 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Joel Mark</td>\n",
       "      <td>24</td>\n",
       "      <td>Lobby 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Standings      Team.1  Total    Lobby\n",
       "0        1.0  FC Destroy    112  Lobby 1\n",
       "1        2.0         Dps     38  Lobby 1\n",
       "2        3.0        CJAM     32  Lobby 1\n",
       "3        4.0        sspZ     31  Lobby 1\n",
       "4        5.0   Joel Mark     24  Lobby 1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to add a column with the lobby so that when we add the files we know what lobby it is in\n",
    "\n",
    "df['Lobby'] = 'Lobby 1'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9db10f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for all files\n",
    "all_lobbies = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    temp = pd.read_csv(f\"{directory}/{file}\")\n",
    "    lobby = str(file).strip(\"'\").replace('_cleaned.csv','') # We don't want the end here\n",
    "    temp['Lobby'] = lobby\n",
    "    all_lobbies = pd.concat([all_lobbies,temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68385428",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'{directory}/Combined'): # check if the folder exists, otherwise make it\n",
    "    os.mkdir(f'{directory}/Combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b403191",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lobbies.to_csv(f'{directory}/Combined/all_lobbies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6e764352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_gen(directory):\n",
    "    if not os.path.exists(f'{directory}/Combined'): # check if the folder exists, otherwise make it\n",
    "        os.mkdir(f'{directory}/Combined')\n",
    "        \n",
    "def lobby_combiner(directory):\n",
    "    all_lobbies = pd.DataFrame()\n",
    "\n",
    "    for file in os.listdir(directory):\n",
    "        if file != 'Combined':\n",
    "            temp = pd.read_csv(f\"{directory}/{file}\")\n",
    "            lobby = str(file).strip(\"'\").replace('_cleaned.csv','') # We don't want the end here\n",
    "            temp['Lobby'] = lobby\n",
    "            all_lobbies = pd.concat([all_lobbies,temp])\n",
    "            \n",
    "    return all_lobbies\n",
    "\n",
    "def round_combiner(region, split, circuit, round_)\n",
    "    outer_dir = f'../Outputs/{region}/{split}/{circuit}'\n",
    "    directory = f'{outer_dir}/{round_}'\n",
    "    \n",
    "    temp = pd.read_csv(f\"{directory}/all_second.csv\")\n",
    "    temp['Region'] = region\n",
    "    all_region_pql = pd.concat([all_region_pql, temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81d9b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = ['Round_1', 'Round_2', 'Round_3','Quarterfinals', 'Semifinals', 'Finals']\n",
    "\n",
    "for r in rounds:\n",
    "    directory = f'../Outputs/APAC_North/Preseason_Qualifier_1/{r}/Cleaned'\n",
    "    \n",
    "    folder_gen(directory)\n",
    "    \n",
    "    final_df = lobby_combiner(directory)\n",
    "    final_df.to_csv(f'{directory}/Combined/{r}_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c239bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\"APAC_North\", \"APAC_South\", \"EMEA\", \"North_America\", \"South_America\"]\n",
    "pqls = ['Preseason_Qualifier_1', 'Preseason_Qualifier_2', 'Preseason_Qualifier_3', 'Preseason_Qualifier_4']\n",
    "rounds = ['Round_1', 'Round_2', 'Round_3','Quarterfinals', 'Semifinals', 'Finals']\n",
    "\n",
    "\n",
    "for region in regions:\n",
    "    for pql in pqls:\n",
    "        for r in rounds:\n",
    "            directory = f'../Outputs/{region}/{pql}/{r}/Cleaned'\n",
    "    \n",
    "            folder_gen(directory)\n",
    "\n",
    "            final_df = lobby_combiner(directory)\n",
    "            final_df.to_csv(f'{directory}/Combined/{r}_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6950d366",
   "metadata": {},
   "source": [
    "Now combining the rounds of PQL into each PQL folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c0aee639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PQL 1 has diff format for Rounds 1-3 and QF -> Finals\n",
    "outter_dir = f'../Outputs/APAC_North/Preseason_Qualifier_1'\n",
    "first_rounds = ['Round_1', 'Round_2', 'Round_3']\n",
    "second_rounds = ['Quarterfinals', 'Semifinals', 'Finals']\n",
    "\n",
    "all_first = pd.DataFrame()\n",
    "all_second = pd.DataFrame()\n",
    "\n",
    "for r in first_rounds:\n",
    "    directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "    try:\n",
    "        temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "        temp['Round'] = f'{r}'\n",
    "        all_first = pd.concat([all_first,temp])\n",
    "    except pd.errors.EmptyDataError:\n",
    "        continue\n",
    "\n",
    "    \n",
    "for r in second_rounds:\n",
    "    directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "    temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "    temp['Round'] = f'{r}'\n",
    "    all_second = pd.concat([all_second,temp])\n",
    "   \n",
    "    \n",
    "all_first.to_csv(f'{outter_dir}/all_first.csv', index=False)\n",
    "all_second.to_csv(f'{outter_dir}/all_second.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39f35581",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\"APAC_North\", \"APAC_South\", \"EMEA\", \"North_America\", \"South_America\"]\n",
    "pqls = ['Preseason_Qualifier_2', 'Preseason_Qualifier_3', 'Preseason_Qualifier_4']\n",
    "first_rounds = ['Round_1', 'Round_2', 'Round_3']\n",
    "second_rounds = ['Quarterfinals', 'Semifinals', 'Finals']\n",
    "\n",
    "for region in regions:\n",
    "    all_first = pd.DataFrame()\n",
    "    all_second = pd.DataFrame()\n",
    "    outter_dir = f'../Outputs/{region}/Preseason_Qualifier_1'\n",
    "    \n",
    "    for r in first_rounds:\n",
    "        directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "        try:\n",
    "            temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "            temp['Round'] = f'{r}'\n",
    "            all_first = pd.concat([all_first,temp])\n",
    "        except pd.errors.EmptyDataError:\n",
    "            continue\n",
    "\n",
    "    \n",
    "    for r in second_rounds:\n",
    "        try:\n",
    "            directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "            temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "            temp['Round'] = f'{r}'\n",
    "            all_second = pd.concat([all_second,temp])\n",
    "        except pd.errors.EmptyDataError:\n",
    "            continue\n",
    "        \n",
    "    all_first.to_csv(f'{outter_dir}/all_first.csv', index=False)\n",
    "    all_second.to_csv(f'{outter_dir}/all_second.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "43e6c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PQL 2-4 are fine\n",
    "regions = [\"APAC_North\", \"APAC_South\", \"EMEA\", \"North_America\", \"South_America\"]\n",
    "pqls = ['Preseason_Qualifier_2', 'Preseason_Qualifier_3', 'Preseason_Qualifier_4']\n",
    "rounds = ['Round_1', 'Round_2', 'Round_3','Quarterfinals', 'Semifinals', 'Finals']\n",
    "\n",
    "for region in regions:\n",
    "    for pql in pqls:\n",
    "        outter_dir = f'../Outputs/{region}/{pql}'\n",
    "        all_rounds = pd.DataFrame()\n",
    "        \n",
    "        for r in rounds:\n",
    "            try:\n",
    "                directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "                temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "                temp['Round'] = f'{r}'\n",
    "                all_rounds = pd.concat([all_rounds, temp])\n",
    "            except pd.errors.EmptyDataError:\n",
    "                continue\n",
    "            \n",
    "        all_rounds.to_csv(f'{outter_dir}/all_rounds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48f0c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIALTY TWEAKS FOR EMEA PQ 1 ROUND 2 AND UP\n",
    "directory = \"../Outputs/EMEA/Preseason_Qualifier_1/Round_2/Cleaned\"\n",
    "\n",
    "final_df = lobby_combiner(directory)\n",
    "final_df.to_csv(f\"{directory}/Combined/Round_2_combined.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbfb2768",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\"EMEA\"]\n",
    "first_rounds = ['Round_1']\n",
    "second_rounds = ['Round_2','Quarterfinals', 'Semifinals', 'Finals']\n",
    "\n",
    "\n",
    "for region in regions:\n",
    "    all_first = pd.DataFrame()\n",
    "    all_second = pd.DataFrame()\n",
    "    outter_dir = f'../Outputs/{region}/Preseason_Qualifier_1'\n",
    "    \n",
    "    for r in first_rounds:\n",
    "        directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "        try:\n",
    "            temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "            temp['Round'] = f'{r}'\n",
    "            all_first = pd.concat([all_first,temp])\n",
    "        except pd.errors.EmptyDataError:\n",
    "            continue\n",
    "\n",
    "    \n",
    "    for r in second_rounds:\n",
    "        try:\n",
    "            directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "            temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "            temp['Round'] = f'{r}'\n",
    "            all_second = pd.concat([all_second,temp])\n",
    "        except pd.errors.EmptyDataError:\n",
    "            continue\n",
    "        \n",
    "    all_first.to_csv(f'{outter_dir}/all_first.csv', index=False)\n",
    "    all_second.to_csv(f'{outter_dir}/all_second.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c597dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIALTY TWEAKS FOR SOUTH AM PQ 1 ROUND 1 TO SEMIS\n",
    "rounds = ['Round_1', 'Quarterfinals', 'Semifinals']\n",
    "\n",
    "for r in rounds:\n",
    "    directory = f\"../Outputs/South_America/Preseason_Qualifier_1/{r}/Cleaned\"\n",
    "    \n",
    "    final_df = lobby_combiner(directory)\n",
    "    final_df.to_csv(f\"{directory}/Combined/{r}_combined.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "548ec8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\"South_America\"]\n",
    "first_rounds = ['Round_1', 'Quarterfinals', 'Semifinals']\n",
    "second_rounds = ['Finals']\n",
    "\n",
    "\n",
    "for region in regions:\n",
    "    all_first = pd.DataFrame()\n",
    "    all_second = pd.DataFrame()\n",
    "    outter_dir = f'../Outputs/{region}/Preseason_Qualifier_1'\n",
    "    \n",
    "    for r in first_rounds:\n",
    "        directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "        try:\n",
    "            temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "            temp['Round'] = f'{r}'\n",
    "            all_first = pd.concat([all_first,temp])\n",
    "        except pd.errors.EmptyDataError:\n",
    "            continue\n",
    "\n",
    "    \n",
    "    for r in second_rounds:\n",
    "        try:\n",
    "            directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "            temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "            temp['Round'] = f'{r}'\n",
    "            all_second = pd.concat([all_second,temp])\n",
    "        except pd.errors.EmptyDataError:\n",
    "            continue\n",
    "        \n",
    "    all_first.to_csv(f'{outter_dir}/all_first.csv', index=False)\n",
    "    all_second.to_csv(f'{outter_dir}/all_second.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "166a3512",
   "metadata": {},
   "outputs": [],
   "source": [
    "## APAC SOUTH R1 and QF\n",
    "regions = [\"APAC_South\"]\n",
    "first_rounds = ['Round_1', 'Quarterfinals']\n",
    "second_rounds = ['Semifinals', 'Finals']\n",
    "\n",
    "\n",
    "for region in regions:\n",
    "    all_first = pd.DataFrame()\n",
    "    all_second = pd.DataFrame()\n",
    "    outter_dir = f'../Outputs/{region}/Preseason_Qualifier_1'\n",
    "    \n",
    "    for r in first_rounds:\n",
    "        directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "        try:\n",
    "            temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "            temp['Round'] = f'{r}'\n",
    "            all_first = pd.concat([all_first,temp])\n",
    "        except pd.errors.EmptyDataError:\n",
    "            continue\n",
    "\n",
    "    \n",
    "    for r in second_rounds:\n",
    "        try:\n",
    "            directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "            temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "            temp['Round'] = f'{r}'\n",
    "            all_second = pd.concat([all_second,temp])\n",
    "        except pd.errors.EmptyDataError:\n",
    "            continue\n",
    "        \n",
    "    all_first.to_csv(f'{outter_dir}/all_first.csv', index=False)\n",
    "    all_second.to_csv(f'{outter_dir}/all_second.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4c0b4e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all preseason 1 second half and preseason 2-4 quals into one big file\n",
    "\n",
    "regions = [\"APAC_North\", \"APAC_South\", \"EMEA\", \"North_America\", \"South_America\"]\n",
    "pqls = ['Preseason_Qualifier_1','Preseason_Qualifier_2', 'Preseason_Qualifier_3', 'Preseason_Qualifier_4']\n",
    "\n",
    "for region in regions:\n",
    "    outer_dir = f'../Outputs/{region}'\n",
    "    all_pqls = pd.DataFrame()\n",
    "    \n",
    "    for pql in pqls:\n",
    "        \n",
    "        directory = f'{outer_dir}/{pql}'\n",
    "        \n",
    "        if pql == 'Preseason_Qualifier_1':\n",
    "            temp = pd.read_csv(f\"{directory}/all_second.csv\")\n",
    "            temp['PQL'] = pql\n",
    "            all_pqls = pd.concat([all_pqls, temp])\n",
    "        else:\n",
    "            temp = pd.read_csv(f\"{directory}/all_rounds.csv\")\n",
    "            temp['PQL'] = pql\n",
    "            all_pqls = pd.concat([all_pqls, temp])\n",
    "    \n",
    "    all_pqls.to_csv(f'{outer_dir}/all_pqls_noPQ1Rounds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "28e40243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all PQ1 first half for all regions\n",
    "\n",
    "regions = [\"APAC_North\", \"APAC_South\", \"EMEA\", \"North_America\", \"South_America\"]\n",
    "\n",
    "all_region_pql = pd.DataFrame()\n",
    "\n",
    "\n",
    "for region in regions:\n",
    "    outer_dir = f'../Outputs/{region}'\n",
    "    directory = f'{outer_dir}/Preseason_Qualifier_1'\n",
    "    temp = pd.read_csv(f\"{directory}/all_first.csv\")\n",
    "    temp['Region'] = region\n",
    "    all_region_pql = pd.concat([all_region_pql, temp])\n",
    "    \n",
    "all_region_pql.to_csv(f'../Outputs/Combined Region Data/all_region_PQL1Rounds.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1c187c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all PQ1 second half for all regions\n",
    "\n",
    "regions = [\"APAC_North\", \"APAC_South\", \"EMEA\", \"North_America\", \"South_America\"]\n",
    "\n",
    "all_region_pql = pd.DataFrame()\n",
    "\n",
    "\n",
    "for region in regions:\n",
    "    outer_dir = f'../Outputs/{region}'\n",
    "    directory = f'{outer_dir}/Preseason_Qualifier_1'\n",
    "    temp = pd.read_csv(f\"{directory}/all_second.csv\")\n",
    "    temp['Region'] = region\n",
    "    all_region_pql = pd.concat([all_region_pql, temp])\n",
    "    \n",
    "all_region_pql.to_csv(f'../Outputs/Combined Region Data/all_region_PQL1SecondHalf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "69ed4a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining PQ2-4 for all regions\n",
    "regions = [\"APAC_North\", \"APAC_South\", \"EMEA\", \"North_America\", \"South_America\"]\n",
    "pqls = ['Preseason_Qualifier_2', 'Preseason_Qualifier_3', 'Preseason_Qualifier_4']\n",
    "all_region_pql = pd.DataFrame()\n",
    "\n",
    "for region in regions:\n",
    "    directory = f'../Outputs/{region}'\n",
    "    temp = pd.read_csv(f\"{directory}/all_pqls_noPQ1Rounds.csv\")\n",
    "    temp['Region'] = region\n",
    "    all_region_pql = pd.concat([all_region_pql, temp])\n",
    "\n",
    "all_region_pql.to_csv(f'../Outputs/Combined Region Data/all_region_PQLs_noPQ1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2da16",
   "metadata": {},
   "source": [
    "# Challenger Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5ba2368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\"APAC_North\", \"APAC_South\", \"EMEA\", \"North_America\", \"South_America\"]\n",
    "split = ['Split_1','Split_2']\n",
    "chall_circuit = ['Challenger_Circuit_1', 'Challenger_Circuit_2', 'Challenger_Circuit_3', 'Challenger_Circuit_4']\n",
    "rounds = ['Round_1', 'Round_2', 'Round_3','Quarterfinals', 'Semifinals', 'Finals']\n",
    "\n",
    "for region in regions:\n",
    "    for s in split:\n",
    "        for c in chall_circuit:\n",
    "            for r in rounds:\n",
    "                directory = f'../Outputs/{region}/{s}/{c}/{r}/Cleaned'\n",
    "                \n",
    "                try:\n",
    "                    folder_gen(directory)\n",
    "                    final_df = lobby_combiner(directory)\n",
    "                    final_df.to_csv(f'{directory}/Combined/{r}_combined.csv', index=False)\n",
    "                except FileNotFoundError:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8eac45b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\"APAC_North\", \"APAC_South\", \"EMEA\", \"North_America\", \"South_America\"]\n",
    "split = ['Split_1','Split_2']\n",
    "chall_circuit = ['Challenger_Circuit_1', 'Challenger_Circuit_2', 'Challenger_Circuit_3', 'Challenger_Circuit_4']\n",
    "rounds = ['Round_1', 'Quarterfinals', 'Semifinals', 'Finals']\n",
    "\n",
    "for region in regions:\n",
    "    for s in split:\n",
    "        for c in chall_circuit:\n",
    "            circuit_df = pd.DataFrame()\n",
    "            outter_dir = f'../Outputs/{region}/{s}/{c}'\n",
    "            \n",
    "            for r in rounds:\n",
    "                try:\n",
    "                    directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "                    temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "                    temp['Round'] = f'{r}'\n",
    "                    circuit_df = pd.concat([circuit_df, temp])   \n",
    "                except FileNotFoundError:\n",
    "                    continue\n",
    "                \n",
    "            circuit_df.to_csv(f'{outter_dir}/{c}_combined.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "72d8cb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in regions:\n",
    "    for s in split:\n",
    "        split_df = pd.DataFrame()\n",
    "        outter_dir = f'../Outputs/{region}/{s}'\n",
    "        for c in chall_circuit:\n",
    "            try:\n",
    "                directory = f'{outter_dir}/{c}'\n",
    "                temp = pd.read_csv(f\"{directory}/{c}_combined.csv\")\n",
    "                temp['Split'] = f'{s}'\n",
    "                split_df = pd.concat([split_df, temp])   \n",
    "            except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "                continue\n",
    "\n",
    "        split_df.to_csv(f'{outter_dir}/{s}_combined.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a926643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in regions:\n",
    "    region_df = pd.DataFrame()\n",
    "    outter_dir = f'../Outputs/{region}'\n",
    "    for s in split:\n",
    "        try:\n",
    "            directory = f'{outter_dir}/{s}'\n",
    "            temp = pd.read_csv(f\"{directory}/{s}_combined.csv\")\n",
    "            temp['Region'] = f'{region}'\n",
    "            region_df = pd.concat([region_df, temp])   \n",
    "        except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "            continue\n",
    "\n",
    "    region_df.to_csv(f'{outter_dir}/{region}_cc_combined.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fe64c9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_region_cc = pd.DataFrame()\n",
    "\n",
    "for region in regions:\n",
    "    directory = f'../Outputs/{region}'\n",
    "    temp = pd.read_csv(f\"{directory}/{region}_cc_combined.csv\")\n",
    "    temp['Region'] = region\n",
    "    all_region_cc = pd.concat([all_region_cc, temp])\n",
    "\n",
    "all_region_cc.to_csv(f'../Outputs/Combined Region Data/all_region_cc.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
