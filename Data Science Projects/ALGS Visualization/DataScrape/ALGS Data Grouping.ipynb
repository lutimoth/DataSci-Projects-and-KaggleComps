{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de2d08d8",
   "metadata": {},
   "source": [
    "# Data Restructure\n",
    "\n",
    "We will now attempt to combine our data and convert it into a more visualization friendly long format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c75e96",
   "metadata": {},
   "source": [
    "## Start by combining files in a folder\n",
    "\n",
    "We will follow the following steps:\n",
    "1. collect all games/lobbies of the same round\n",
    "2. collect all rounds of the same level\n",
    "2. collect all levels\n",
    "3. collect all regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0810a4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32d2279c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standings</th>\n",
       "      <th>Team.1</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>FC Destroy</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Dps</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>CJAM</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>sspZ</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Joel Mark</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Standings      Team.1  Total\n",
       "0        1.0  FC Destroy    112\n",
       "1        2.0         Dps     38\n",
       "2        3.0        CJAM     32\n",
       "3        4.0        sspZ     31\n",
       "4        5.0   Joel Mark     24"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with looking at our cleaned data:\n",
    "directory = '../Outputs/APAC_North/Preseason_Qualifier_1/Round_1/Cleaned'\n",
    "\n",
    "df = pd.read_csv(f\"{directory}/Lobby 1_cleaned.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "659678eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standings</th>\n",
       "      <th>Team.1</th>\n",
       "      <th>Total</th>\n",
       "      <th>Lobby</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>FC Destroy</td>\n",
       "      <td>112</td>\n",
       "      <td>Lobby 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Dps</td>\n",
       "      <td>38</td>\n",
       "      <td>Lobby 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>CJAM</td>\n",
       "      <td>32</td>\n",
       "      <td>Lobby 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>sspZ</td>\n",
       "      <td>31</td>\n",
       "      <td>Lobby 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Joel Mark</td>\n",
       "      <td>24</td>\n",
       "      <td>Lobby 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Standings      Team.1  Total    Lobby\n",
       "0        1.0  FC Destroy    112  Lobby 1\n",
       "1        2.0         Dps     38  Lobby 1\n",
       "2        3.0        CJAM     32  Lobby 1\n",
       "3        4.0        sspZ     31  Lobby 1\n",
       "4        5.0   Joel Mark     24  Lobby 1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to add a column with the lobby so that when we add the files we know what lobby it is in\n",
    "\n",
    "df['Lobby'] = 'Lobby 1'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9db10f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for all files\n",
    "all_lobbies = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    temp = pd.read_csv(f\"{directory}/{file}\")\n",
    "    lobby = str(file).strip(\"'\").replace('_cleaned.csv','') # We don't want the end here\n",
    "    temp['Lobby'] = lobby\n",
    "    all_lobbies = pd.concat([all_lobbies,temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68385428",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'{directory}/Combined'): # check if the folder exists, otherwise make it\n",
    "    os.mkdir(f'{directory}/Combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b403191",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lobbies.to_csv(f'{directory}/Combined/all_lobbies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6e764352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_gen(directory):\n",
    "    if not os.path.exists(f'{directory}/Combined'): # check if the folder exists, otherwise make it\n",
    "        os.mkdir(f'{directory}/Combined')\n",
    "        \n",
    "def lobby_combiner(directory):\n",
    "    all_lobbies = pd.DataFrame()\n",
    "\n",
    "    for file in os.listdir(directory):\n",
    "        if file != 'Combined':\n",
    "            temp = pd.read_csv(f\"{directory}/{file}\")\n",
    "            lobby = str(file).strip(\"'\").replace('_cleaned.csv','') # We don't want the end here\n",
    "            temp['Lobby'] = lobby\n",
    "            all_lobbies = pd.concat([all_lobbies,temp])\n",
    "            \n",
    "    return all_lobbies\n",
    "\n",
    "def round_combiner(region, split, circuit, round_)\n",
    "    outer_dir = f'../Outputs/{region}/{split}/{circuit}'\n",
    "    directory = f'{outer_dir}/{round_}'\n",
    "    \n",
    "    temp = pd.read_csv(f\"{directory}/all_second.csv\")\n",
    "    temp['Region'] = region\n",
    "    all_region_pql = pd.concat([all_region_pql, temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81d9b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = ['Round_1', 'Round_2', 'Round_3','Quarterfinals', 'Semifinals', 'Finals']\n",
    "\n",
    "for r in rounds:\n",
    "    directory = f'../Outputs/APAC_North/Preseason_Qualifier_1/{r}/Cleaned'\n",
    "    \n",
    "    folder_gen(directory)\n",
    "    \n",
    "    final_df = lobby_combiner(directory)\n",
    "    final_df.to_csv(f'{directory}/Combined/{r}_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c239bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\"APAC_North\", \"APAC_South\", \"EMEA\", \"North_America\", \"South_America\"]\n",
    "pqls = ['Preseason_Qualifier_1', 'Preseason_Qualifier_2', 'Preseason_Qualifier_3', 'Preseason_Qualifier_4']\n",
    "rounds = ['Round_1', 'Round_2', 'Round_3','Quarterfinals', 'Semifinals', 'Finals']\n",
    "\n",
    "\n",
    "for region in regions:\n",
    "    for pql in pqls:\n",
    "        for r in rounds:\n",
    "            directory = f'../Outputs/{region}/{pql}/{r}/Cleaned'\n",
    "    \n",
    "            folder_gen(directory)\n",
    "\n",
    "            final_df = lobby_combiner(directory)\n",
    "            final_df.to_csv(f'{directory}/Combined/{r}_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6950d366",
   "metadata": {},
   "source": [
    "Now combining the rounds of PQL into each PQL folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c0aee639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PQL 1 has diff format for Rounds 1-3 and QF -> Finals\n",
    "outter_dir = f'../Outputs/APAC_North/Preseason_Qualifier_1'\n",
    "first_rounds = ['Round_1', 'Round_2', 'Round_3']\n",
    "second_rounds = ['Quarterfinals', 'Semifinals', 'Finals']\n",
    "\n",
    "all_first = pd.DataFrame()\n",
    "all_second = pd.DataFrame()\n",
    "\n",
    "for r in first_rounds:\n",
    "    directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "    try:\n",
    "        temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "        temp['Round'] = f'{r}'\n",
    "        all_first = pd.concat([all_first,temp])\n",
    "    except pd.errors.EmptyDataError:\n",
    "        continue\n",
    "\n",
    "    \n",
    "for r in second_rounds:\n",
    "    directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "    temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "    temp['Round'] = f'{r}'\n",
    "    all_second = pd.concat([all_second,temp])\n",
    "   \n",
    "    \n",
    "all_first.to_csv(f'{outter_dir}/all_first.csv', index=False)\n",
    "all_second.to_csv(f'{outter_dir}/all_second.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39f35581",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\"APAC_North\", \"APAC_South\", \"EMEA\", \"North_America\", \"South_America\"]\n",
    "pqls = ['Preseason_Qualifier_2', 'Preseason_Qualifier_3', 'Preseason_Qualifier_4']\n",
    "first_rounds = ['Round_1', 'Round_2', 'Round_3']\n",
    "second_rounds = ['Quarterfinals', 'Semifinals', 'Finals']\n",
    "\n",
    "for region in regions:\n",
    "    all_first = pd.DataFrame()\n",
    "    all_second = pd.DataFrame()\n",
    "    outter_dir = f'../Outputs/{region}/Preseason_Qualifier_1'\n",
    "    \n",
    "    for r in first_rounds:\n",
    "        directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "        try:\n",
    "            temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "            temp['Round'] = f'{r}'\n",
    "            all_first = pd.concat([all_first,temp])\n",
    "        except pd.errors.EmptyDataError:\n",
    "            continue\n",
    "\n",
    "    \n",
    "    for r in second_rounds:\n",
    "        try:\n",
    "            directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "            temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "            temp['Round'] = f'{r}'\n",
    "            all_second = pd.concat([all_second,temp])\n",
    "        except pd.errors.EmptyDataError:\n",
    "            continue\n",
    "        \n",
    "    all_first.to_csv(f'{outter_dir}/all_first.csv', index=False)\n",
    "    all_second.to_csv(f'{outter_dir}/all_second.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "43e6c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PQL 2-4 are fine\n",
    "regions = [\"APAC_North\", \"APAC_South\", \"EMEA\", \"North_America\", \"South_America\"]\n",
    "pqls = ['Preseason_Qualifier_2', 'Preseason_Qualifier_3', 'Preseason_Qualifier_4']\n",
    "rounds = ['Round_1', 'Round_2', 'Round_3','Quarterfinals', 'Semifinals', 'Finals']\n",
    "\n",
    "for region in regions:\n",
    "    for pql in pqls:\n",
    "        outter_dir = f'../Outputs/{region}/{pql}'\n",
    "        all_rounds = pd.DataFrame()\n",
    "        \n",
    "        for r in rounds:\n",
    "            try:\n",
    "                directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "                temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "                temp['Round'] = f'{r}'\n",
    "                all_rounds = pd.concat([all_rounds, temp])\n",
    "            except pd.errors.EmptyDataError:\n",
    "                continue\n",
    "            \n",
    "        all_rounds.to_csv(f'{outter_dir}/all_rounds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a946aaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIALTY TWEAKS FOR EMEA PQ 1 ROUND 2 AND UP\n",
    "directory = \"../Outputs/EMEA/Preseason_Qualifier_1/Round_2/Cleaned\"\n",
    "\n",
    "final_df = lobby_combiner(directory)\n",
    "final_df.to_csv(f\"{directory}/Combined/Round_2_combined.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61afa364",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\"EMEA\"]\n",
    "first_rounds = ['Round_1']\n",
    "second_rounds = ['Round_2','Quarterfinals', 'Semifinals', 'Finals']\n",
    "\n",
    "\n",
    "for region in regions:\n",
    "    all_first = pd.DataFrame()\n",
    "    all_second = pd.DataFrame()\n",
    "    outter_dir = f'../Outputs/{region}/Preseason_Qualifier_1'\n",
    "    \n",
    "    for r in first_rounds:\n",
    "        directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "        try:\n",
    "            temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "            temp['Round'] = f'{r}'\n",
    "            all_first = pd.concat([all_first,temp])\n",
    "        except pd.errors.EmptyDataError:\n",
    "            continue\n",
    "\n",
    "    \n",
    "    for r in second_rounds:\n",
    "        try:\n",
    "            directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "            temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "            temp['Round'] = f'{r}'\n",
    "            all_second = pd.concat([all_second,temp])\n",
    "        except pd.errors.EmptyDataError:\n",
    "            continue\n",
    "        \n",
    "    all_first.to_csv(f'{outter_dir}/all_first.csv', index=False)\n",
    "    all_second.to_csv(f'{outter_dir}/all_second.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34fa1ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPECIALTY TWEAKS FOR SOUTH AM PQ 1 ROUND 1 TO SEMIS\n",
    "rounds = ['Round_1', 'Quarterfinals', 'Semifinals']\n",
    "\n",
    "for r in rounds:\n",
    "    directory = f\"../Outputs/South_America/Preseason_Qualifier_1/{r}/Cleaned\"\n",
    "    \n",
    "    final_df = lobby_combiner(directory)\n",
    "    final_df.to_csv(f\"{directory}/Combined/{r}_combined.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d2271844",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\"South_America\"]\n",
    "first_rounds = ['Round_1', 'Quarterfinals', 'Semifinals']\n",
    "second_rounds = ['Finals']\n",
    "\n",
    "\n",
    "for region in regions:\n",
    "    all_first = pd.DataFrame()\n",
    "    all_second = pd.DataFrame()\n",
    "    outter_dir = f'../Outputs/{region}/Preseason_Qualifier_1'\n",
    "    \n",
    "    for r in first_rounds:\n",
    "        directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "        try:\n",
    "            temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "            temp['Round'] = f'{r}'\n",
    "            all_first = pd.concat([all_first,temp])\n",
    "        except pd.errors.EmptyDataError:\n",
    "            continue\n",
    "\n",
    "    \n",
    "    for r in second_rounds:\n",
    "        try:\n",
    "            directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "            temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "            temp['Round'] = f'{r}'\n",
    "            all_second = pd.concat([all_second,temp])\n",
    "        except pd.errors.EmptyDataError:\n",
    "            continue\n",
    "        \n",
    "    all_first.to_csv(f'{outter_dir}/all_first.csv', index=False)\n",
    "    all_second.to_csv(f'{outter_dir}/all_second.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6e001c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## APAC SOUTH R1 and QF\n",
    "regions = [\"APAC_South\"]\n",
    "first_rounds = ['Round_1', 'Quarterfinals']\n",
    "second_rounds = ['Semifinals', 'Finals']\n",
    "\n",
    "\n",
    "for region in regions:\n",
    "    all_first = pd.DataFrame()\n",
    "    all_second = pd.DataFrame()\n",
    "    outter_dir = f'../Outputs/{region}/Preseason_Qualifier_1'\n",
    "    \n",
    "    for r in first_rounds:\n",
    "        directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "        try:\n",
    "            temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "            temp['Round'] = f'{r}'\n",
    "            all_first = pd.concat([all_first,temp])\n",
    "        except pd.errors.EmptyDataError:\n",
    "            continue\n",
    "\n",
    "    \n",
    "    for r in second_rounds:\n",
    "        try:\n",
    "            directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "            temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "            temp['Round'] = f'{r}'\n",
    "            all_second = pd.concat([all_second,temp])\n",
    "        except pd.errors.EmptyDataError:\n",
    "            continue\n",
    "        \n",
    "    all_first.to_csv(f'{outter_dir}/all_first.csv', index=False)\n",
    "    all_second.to_csv(f'{outter_dir}/all_second.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "86dc16d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all preseason 1 second half and preseason 2-4 quals into one big file\n",
    "\n",
    "regions = [\"APAC_North\", \"APAC_South\", \"EMEA\", \"North_America\", \"South_America\"]\n",
    "pqls = ['Preseason_Qualifier_1','Preseason_Qualifier_2', 'Preseason_Qualifier_3', 'Preseason_Qualifier_4']\n",
    "\n",
    "for region in regions:\n",
    "    outer_dir = f'../Outputs/{region}'\n",
    "    all_pqls = pd.DataFrame()\n",
    "    \n",
    "    for pql in pqls:\n",
    "        \n",
    "        directory = f'{outer_dir}/{pql}'\n",
    "        \n",
    "        if pql == 'Preseason_Qualifier_1':\n",
    "            temp = pd.read_csv(f\"{directory}/all_second.csv\")\n",
    "            temp['PQL'] = pql\n",
    "            all_pqls = pd.concat([all_pqls, temp])\n",
    "        else:\n",
    "            temp = pd.read_csv(f\"{directory}/all_rounds.csv\")\n",
    "            temp['PQL'] = pql\n",
    "            all_pqls = pd.concat([all_pqls, temp])\n",
    "    \n",
    "    all_pqls.to_csv(f'{outer_dir}/all_pqls_noPQ1Rounds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0863a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all PQ1 first half for all regions\n",
    "\n",
    "regions = [\"APAC_North\", \"APAC_South\", \"EMEA\", \"North_America\", \"South_America\"]\n",
    "\n",
    "all_region_pql = pd.DataFrame()\n",
    "\n",
    "\n",
    "for region in regions:\n",
    "    outer_dir = f'../Outputs/{region}'\n",
    "    directory = f'{outer_dir}/Preseason_Qualifier_1'\n",
    "    temp = pd.read_csv(f\"{directory}/all_first.csv\")\n",
    "    temp['Region'] = region\n",
    "    all_region_pql = pd.concat([all_region_pql, temp])\n",
    "    \n",
    "all_region_pql.to_csv(f'../Outputs/Combined Region Data/all_region_PQL1Rounds.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bd8c8b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all PQ1 second half for all regions\n",
    "\n",
    "regions = [\"APAC_North\", \"APAC_South\", \"EMEA\", \"North_America\", \"South_America\"]\n",
    "\n",
    "all_region_pql = pd.DataFrame()\n",
    "\n",
    "\n",
    "for region in regions:\n",
    "    outer_dir = f'../Outputs/{region}'\n",
    "    directory = f'{outer_dir}/Preseason_Qualifier_1'\n",
    "    temp = pd.read_csv(f\"{directory}/all_second.csv\")\n",
    "    temp['Region'] = region\n",
    "    all_region_pql = pd.concat([all_region_pql, temp])\n",
    "    \n",
    "all_region_pql.to_csv(f'../Outputs/Combined Region Data/all_region_PQL1SecondHalf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "16ab67ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining PQ2-4 for all regions\n",
    "regions = [\"APAC_North\", \"APAC_South\", \"EMEA\", \"North_America\", \"South_America\"]\n",
    "pqls = ['Preseason_Qualifier_2', 'Preseason_Qualifier_3', 'Preseason_Qualifier_4']\n",
    "all_region_pql = pd.DataFrame()\n",
    "\n",
    "for region in regions:\n",
    "    directory = f'../Outputs/{region}'\n",
    "    temp = pd.read_csv(f\"{directory}/all_pqls_noPQ1Rounds.csv\")\n",
    "    temp['Region'] = region\n",
    "    all_region_pql = pd.concat([all_region_pql, temp])\n",
    "\n",
    "all_region_pql.to_csv(f'../Outputs/Combined Region Data/all_region_PQLs_noPQ1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb7abd4",
   "metadata": {},
   "source": [
    "# Challenger Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1a38423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\"APAC_North\", \"APAC_South\", \"EMEA\", \"North_America\", \"South_America\"]\n",
    "split = ['Split_1','Split_2']\n",
    "chall_circuit = ['Challenger_Circuit_1', 'Challenger_Circuit_2', 'Challenger_Circuit_3', 'Challenger_Circuit_4']\n",
    "rounds = ['Round_1', 'Round_2', 'Round_3','Quarterfinals', 'Semifinals', 'Finals']\n",
    "\n",
    "for region in regions:\n",
    "    for s in split:\n",
    "        for c in chall_circuit:\n",
    "            for r in rounds:\n",
    "                directory = f'../Outputs/{region}/{s}/{c}/{r}/Cleaned'\n",
    "                \n",
    "                try:\n",
    "                    folder_gen(directory)\n",
    "                    final_df = lobby_combiner(directory)\n",
    "                    final_df.to_csv(f'{directory}/Combined/{r}_combined.csv', index=False)\n",
    "                except FileNotFoundError:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "37dd7a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\"APAC_North\", \"APAC_South\", \"EMEA\", \"North_America\", \"South_America\"]\n",
    "split = ['Split_1','Split_2']\n",
    "chall_circuit = ['Challenger_Circuit_1', 'Challenger_Circuit_2', 'Challenger_Circuit_3', 'Challenger_Circuit_4']\n",
    "rounds = ['Round_1', 'Quarterfinals', 'Semifinals', 'Finals']\n",
    "\n",
    "for region in regions:\n",
    "    for s in split:\n",
    "        for c in chall_circuit:\n",
    "            circuit_df = pd.DataFrame()\n",
    "            outter_dir = f'../Outputs/{region}/{s}/{c}'\n",
    "            \n",
    "            for r in rounds:\n",
    "                try:\n",
    "                    directory = f'{outter_dir}/{r}/Cleaned/Combined'\n",
    "                    temp = pd.read_csv(f\"{directory}/{r}_combined.csv\")\n",
    "                    temp['Round'] = f'{r}'\n",
    "                    circuit_df = pd.concat([circuit_df, temp])   \n",
    "                except FileNotFoundError:\n",
    "                    continue\n",
    "                \n",
    "            circuit_df.to_csv(f'{outter_dir}/{c}_combined.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8bcd88a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in regions:\n",
    "    for s in split:\n",
    "        split_df = pd.DataFrame()\n",
    "        outter_dir = f'../Outputs/{region}/{s}'\n",
    "        for c in chall_circuit:\n",
    "            try:\n",
    "                directory = f'{outter_dir}/{c}'\n",
    "                temp = pd.read_csv(f\"{directory}/{c}_combined.csv\")\n",
    "                temp['Split'] = f'{s}'\n",
    "                split_df = pd.concat([split_df, temp])   \n",
    "            except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "                continue\n",
    "\n",
    "        split_df.to_csv(f'{outter_dir}/{s}_combined.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e38154f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in regions:\n",
    "    region_df = pd.DataFrame()\n",
    "    outter_dir = f'../Outputs/{region}'\n",
    "    for s in split:\n",
    "        try:\n",
    "            directory = f'{outter_dir}/{s}'\n",
    "            temp = pd.read_csv(f\"{directory}/{s}_combined.csv\")\n",
    "            temp['Region'] = f'{region}'\n",
    "            region_df = pd.concat([region_df, temp])   \n",
    "        except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "            continue\n",
    "\n",
    "    region_df.to_csv(f'{outter_dir}/{region}_cc_combined.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5cb807da",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_region_cc = pd.DataFrame()\n",
    "\n",
    "for region in regions:\n",
    "    directory = f'../Outputs/{region}'\n",
    "    temp = pd.read_csv(f\"{directory}/{region}_cc_combined.csv\")\n",
    "    temp['Region'] = region\n",
    "    all_region_cc = pd.concat([all_region_cc, temp])\n",
    "\n",
    "all_region_cc.to_csv(f'../Outputs/Combined Region Data/all_region_cc.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3efcbce",
   "metadata": {},
   "source": [
    "# Playoff Points\n",
    "\n",
    "Playoff goes straight to region combining since there's only one round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e550898",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\"APAC_North\", \"APAC_South\", \"EMEA\", \"North_America\", \"South_America\"]\n",
    "points = [\"Points\",\"Matchpoint\"]\n",
    "playoff_comb = pd.DataFrame()\n",
    "          \n",
    "for region in regions:\n",
    "    \n",
    "    directory = f'../Outputs/{region}/Split_1/Playoffs/Rounds/Cleaned'\n",
    "    temp = pd.read_csv(f\"{directory}/Points_cleaned.csv\")\n",
    "    temp['Region'] = region\n",
    "    playoff_comb = pd.concat([playoff_comb, temp])\n",
    "\n",
    "playoff_comb.to_csv(f'../Outputs/Combined Region Data/all_split1_PlayoffPoints.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1806a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_comb = pd.DataFrame()\n",
    "for region in regions:\n",
    "    directory = f'../Outputs/{region}/Split_1/Playoffs/Rounds/Cleaned'\n",
    "    temp = pd.read_csv(f\"{directory}/Matchpoint_cleaned.csv\")\n",
    "    temp['Region'] = region\n",
    "    mp_comb = pd.concat([mp_comb, temp])\n",
    "\n",
    "mp_comb.to_csv(f'../Outputs/Combined Region Data/all_split1_matchpoints.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc79368",
   "metadata": {},
   "source": [
    "# Pro League Matches\n",
    "\n",
    "2 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "08357350",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\"APAC_North\", \"APAC_South\", \"EMEA\", \"North_America\", \"South_America\"]\n",
    "split = ['Split_1','Split_2']\n",
    "\n",
    "\n",
    "for region in regions:\n",
    "    for s in split:\n",
    "        directory = f'../Outputs/{region}/{s}/Pro_league/Matches/Cleaned'\n",
    "        \n",
    "        folder_gen(directory)\n",
    "        split_df = lobby_combiner(directory)\n",
    "        split_df.to_csv(f'{directory}/Combined/Pro_League_Combined.csv',index=False)\n",
    "    \n",
    "       # split_df.to_csv(f'{outter_dir}/{s}_combined.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "af3f5a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in regions:\n",
    "    split_combined_df = pd.DataFrame()\n",
    "    directory = f'../Outputs/{region}/{s}/Pro_league/Matches/Cleaned'\n",
    "    \n",
    "    for s in split:\n",
    "        temp = pd.read_csv(f'{directory}/Pro_League_Combined.csv')\n",
    "        temp['Split'] = s\n",
    "        split_combined_df = pd.concat([split_combined_df, temp])\n",
    "    split_combined_df.to_csv(f'../Outputs/{region}/Pro_League_Splits_Combined.csv', index=False)\n",
    "    \n",
    "       # split_df.to_csv(f'{outter_dir}/{s}_combined.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3a92d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_comb_df = pd.DataFrame()\n",
    "\n",
    "for region in regions:\n",
    "    directory = f'../Outputs/{region}/'\n",
    "    temp = pd.read_csv(f'{directory}/Pro_League_Splits_Combined.csv')\n",
    "    temp['Region'] = region\n",
    "    pro_comb_df = pd.concat([pro_comb_df, temp])\n",
    "pro_comb_df.to_csv(f'../Outputs/Combined Region Data/All_Region_ProLeague.csv',index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8043270f",
   "metadata": {},
   "source": [
    "# Split 2 Qualifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "86474465",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\"APAC_North\", \"APAC_South\", \"EMEA\", \"North_America\", \"South_America\"]\n",
    "brackets = ['Finals','Losers_Bracket','Winners_Bracket']\n",
    "\n",
    "for region in regions:\n",
    "    qual_comb = pd.DataFrame()\n",
    "    \n",
    "    for bracket in brackets:\n",
    "        directory = f'../Outputs/{region}/Split_2/Pro_League/Qualifiers/{bracket}/Cleaned'\n",
    "        temp = pd.read_csv(f'{directory}/Points_cleaned.csv')\n",
    "        temp['Bracket'] = bracket\n",
    "        qual_comb = pd.concat([qual_comb, temp])\n",
    "    qual_comb.to_csv(f'../Outputs/{region}/Split_2/Pro_League/Qualifiers/Qual_Combined.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "88897e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_quals = pd.DataFrame()\n",
    "\n",
    "for region in regions:\n",
    "    directory = f'../Outputs/{region}/Split_2/Pro_League/Qualifiers/'\n",
    "    temp = pd.read_csv(f'{directory}/Qual_Combined.csv')\n",
    "    temp['Region'] = region\n",
    "    region_quals = pd.concat([region_quals, temp])\n",
    "    \n",
    "region_quals.to_csv(f'../Outputs/Combined Region Data/all_region_quals.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a79f098",
   "metadata": {},
   "source": [
    "# Split 2 Playoffs\n",
    "\n",
    "work with this manually since it is a one-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e3c51cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bracket Stage\n",
    "rounds = ['Round 1_cleaned.csv', 'Round 3_cleaned.csv', 'Round 5_cleaned.csv']\n",
    "bracket_comb = pd.DataFrame()\n",
    "\n",
    "for r in rounds:\n",
    "    temp = pd.read_csv(f'../Outputs/Split 2 Playoffs/Bracket_Stage/Cleaned/{r}')\n",
    "    temp['Stage'] = r.replace('_cleaned.csv','')\n",
    "    bracket_comb = pd.concat([bracket_comb, temp])\n",
    "    \n",
    "bracket_comb.to_csv(f'../Outputs/Split 2 Playoffs/split2_playoff_bracket.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "312d930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = ['Round 1_cleaned.csv', 'Round 2_cleaned.csv', 'Round 3_cleaned.csv', 'Round 4_cleaned.csv', 'Round 5_cleaned.csv', 'Round 6_cleaned.csv']\n",
    "\n",
    "group_comb = pd.DataFrame()\n",
    "for r in rounds:\n",
    "    temp = pd.read_csv(f'../Outputs/Split 2 Playoffs/Group_Stage/Cleaned/{r}')\n",
    "    temp['Stage'] = r.replace('_cleaned.csv','')\n",
    "    group_comb = pd.concat([group_comb, temp])\n",
    "    \n",
    "group_comb.to_csv(f'../Outputs/Split 2 Playoffs/split2_playoff_group.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "84b2f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = f'../Outputs/Split 2 Playoffs/'\n",
    "\n",
    "play_finals = pd.read_csv(f'{directory}/Points_cleaned.csv')\n",
    "play_finals['Round'] = 'Finals'\n",
    "\n",
    "play_group = pd.read_csv(f'{directory}/split2_playoff_group.csv')\n",
    "play_group['Round'] = 'Group Stage'\n",
    "\n",
    "play_brack = pd.read_csv(f'{directory}/split2_playoff_bracket.csv')\n",
    "play_brack['Round'] = 'Bracket Stage'\n",
    "\n",
    "\n",
    "split2_play = pd.concat([play_brack, play_group, play_finals])\n",
    "split2_play.to_csv(f'../Outputs/Combined Region Data/split2_playoffs.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504bf13c",
   "metadata": {},
   "source": [
    "# LCQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3e646469",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [\"APAC_North\", \"APAC_South\", \"EMEA\", \"North_America\", \"South_America\"]\n",
    "lcqs = ['Last_Chance_Qualifier_1', 'Last_Chance_Qualifier_2']\n",
    "brackets = ['Finals','Losers_Bracket','Winners_Bracket']\n",
    "\n",
    "for region in regions:\n",
    "    for lcq in lcqs:\n",
    "        outter_dir = f'../Outputs/{region}/Championship/{lcq}'\n",
    "        lcq_rounds = pd.DataFrame()\n",
    "        for bracket in brackets:\n",
    "            directory = f'{outter_dir}/{bracket}/Cleaned'\n",
    "            temp = pd.read_csv(f'{directory}/Points_cleaned.csv')\n",
    "            temp['Bracket'] = bracket\n",
    "            lcq_rounds = pd.concat([lcq_rounds, temp])\n",
    "        lcq_rounds.to_csv(f'{outter_dir}/lcq_rounds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fd318d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in regions:\n",
    "    outter_dir = f'../Outputs/{region}/Championship/'\n",
    "    lcq_comb = pd.DataFrame()\n",
    "    for lcq in lcqs:\n",
    "        directory = f'{outter_dir}/{lcq}'\n",
    "        temp = pd.read_csv(f'{directory}/lcq_rounds.csv')\n",
    "        temp['LCQ'] = lcq\n",
    "        lcq_comb = pd.concat([lcq_comb, temp])\n",
    "    lcq_comb.to_csv(f'{outter_dir}/lcq_rounds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a137ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lcq = pd.DataFrame()\n",
    "\n",
    "for region in regions:\n",
    "    directory = f'../Outputs/{region}/Championship/'\n",
    "    temp = pd.read_csv(f'{directory}/lcq_rounds.csv')\n",
    "    temp['Region'] = region\n",
    "    all_lcq = pd.concat([all_lcq, temp])\n",
    "    \n",
    "all_lcq.to_csv(f'../Outputs/Combined Region Data/all_region_lcq_rounds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0416a050",
   "metadata": {},
   "source": [
    "# Championship Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a0228637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bracket Stage\n",
    "rounds = ['Round 1_cleaned.csv', 'Round 3_cleaned.csv', 'Round 5_cleaned.csv']\n",
    "bracket_comb = pd.DataFrame()\n",
    "\n",
    "for r in rounds:\n",
    "    temp = pd.read_csv(f'../Outputs/Championship/Bracket_Stage/Cleaned/{r}')\n",
    "    temp['Stage'] = r.replace('_cleaned.csv','')\n",
    "    bracket_comb = pd.concat([bracket_comb, temp])\n",
    "    \n",
    "bracket_comb.to_csv(f'../Outputs/Championship/champ_bracket.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "adf2a6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = ['Round 1_cleaned.csv', 'Round 2_cleaned.csv', 'Round 3_cleaned.csv', 'Round 4_cleaned.csv', 'Round 5_cleaned.csv', 'Round 6_cleaned.csv']\n",
    "\n",
    "group_comb = pd.DataFrame()\n",
    "for r in rounds:\n",
    "    temp = pd.read_csv(f'../Outputs/Championship/Group_Stage/Cleaned/{r}')\n",
    "    temp['Stage'] = r.replace('_cleaned.csv','')\n",
    "    group_comb = pd.concat([group_comb, temp])\n",
    "    \n",
    "group_comb.to_csv(f'../Outputs/Championship/champ_group.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9959f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = f'../Outputs/Championship/'\n",
    "\n",
    "play_finals = pd.read_csv(f'{directory}/Points_cleaned.csv')\n",
    "play_finals['Round'] = 'Finals'\n",
    "\n",
    "play_group = pd.read_csv(f'{directory}/champ_group.csv')\n",
    "play_group['Round'] = 'Group Stage'\n",
    "\n",
    "play_brack = pd.read_csv(f'{directory}/champ_bracket.csv')\n",
    "play_brack['Round'] = 'Bracket Stage'\n",
    "\n",
    "\n",
    "split2_play = pd.concat([play_brack, play_group, play_finals])\n",
    "split2_play.to_csv(f'../Outputs/Combined Region Data/champ_combined.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
